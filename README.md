## Project Description

In this project, an ETL process was performed. Data was loaded into a data warehouse, and KPIs and visualizations were generated from them.
This was done to analyze relevant indicators regarding the hiring process of several candidates.

The pipeline follows a **star schema model** with a fact table for scores and multiple dimension tables:  
- **Fact Table:** `scores_fact_table`  
- **Dimension Tables:** `interviewed_table`, `country_table`, `seniority_table`, `technology_table`, `date_table`

## Project Structure
Workshop1/
│
├── data/
│ ├── candidates.csv # Candidate dataset
│ └── candidatesdw.db # SQLite database generated by ETL
│
├── pics/
│ └── diagrama_estrella.png # Star schema diagram
│
├── src/
│ ├── etl.py # ETL script
│ └── query.py # Analysis queries and visualizations
│
├── .gitignore
└── README.md

# Requirements

- Python 3.10+  
- Libraries: `pandas`, `pandera`,`matplotlib`, `sqlite3` (built-in)

## How to run

1. Run the ETL script:

python src/etl.py

The ETL will generate a SQLite database data/candidatesdw.db containing:

Dimension tables: interviewed_table, country_table, seniority_table, technology_table, date_table

Fact table: scores_fact_table

2. Run Analysis and Visualizations

python src/query.py

Generates KPIs and charts:

- Hires by Technology

- Hires by Year

- Hires by Seniority

- Hires by Country Over Years

- Hires by Years of Experience (YOE)

- Not Hires by Technology
